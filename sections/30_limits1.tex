%!TEX root = ../calculus_tutorial.tex

\section{Limits}
\label{sec:limits}

	Limits are a precise mathematical language for talking about
	infinitely large numbers,
	infinitely small lengths,
	and procedures with an infinite number of steps.
	We use the shorthand ``$\lim$'' to denote limit expressions.
	For example,
	the expression $\lim_{x \to \infty} f(x)$,
	read ``the limit of $f(x)$ as $x$ goes to infinity,''
	describes what happens to $f(x)$ when the input to the function $x$ tends to infinity (gets larger and larger).


	\subsection{Example: Archimedes' approximation to $\pi$}
	% ALT. Archimedes' approximation for area of a circle

		We'll start by looking at a visual example of a math procedure
		% with infinite number of steps
		that was invented by Archimedes of Syracuse around 250 BCE.
		Archimedes wanted to calculate the area of a circle of radius $r=1$.
		Today we know the formula for the are of the circle is $A_{\circ} = \pi r^2$,
		so the area of a circle with radius $r=1$ is $\pi$,
		but try to place yourself in Archimedes's shoes (sandals?)
		and suppose that you don't know the formula yet.

		Archimedes' clever idea was to approximate the circle
		as a regular polygon with $n$ sides inscribed in the circle.
		Figure~\ref{fig:inscribed-hexagon-octagon-dodecagon}
		shows the hexagonal (6-sides),
		octagonal (8-sides),
		and dodecagonal (12-sides) approximations to the circle.

		\begin{figure}[htb]
			\centering
			\includegraphics[width=0.99\columnwidth]{figures/calculus/inscribed-polygons.pdf}%
			\vspace{-3mm}
			\caption{	Approximations to the area of circle using a hexagon,
					an octagon, and a dodecagon inscribed inside a circle of radius $r$.}
			\label{fig:inscribed-hexagon-octagon-dodecagon}
		\end{figure}

		Archimedes computed the area of the $n$-sided regular polygons
		by splitting it up into $2n$ triangular slices,
		like the one shown in Figure~\ref{fig:inscribed-hexagon-octagon-dodecagon}~(b).
		He then compute the area each slice using the formula for the area of a triangle,
		and added up the areas of these $2n$ triangles
		to obtain the total area of the $n$-sided polygon.
		Let's denote $A(n)$ the area approximation
		computed from a $n$-sided polygon.
		Looking at Figure~\ref{fig:inscribed-hexagon-octagon-dodecagon},
		we see the approximations to the area of the circle
		using six-sided and eight-sided polygons are underestimates for the total area.
		However,
		the polygon with $n=12$ is starting to look like a circle,
		and we can use our imagination to see that the approximation $A(n) \approx A_{\circ}$
		will get more and more accurate as $n$ becomes larger and larger.
		Archimedes computed an approximation using a $n=96$ sided polygon,
		but thanks to computers we can push the approximation to much higher values of $n$.
		For example,
		using a 50-sided polygon gives us $A(50) = 3.1\ldots$.
		The approximation with $n=1000$ is accurate to four decimals $A(1000) = 3.1415\ldots$,
		and using $n=10K$ we get an approximation to $\pi$
		that is accurate to six decimals $A(10000) = 3.141592\ldots$.
		See the computational notebook here for the details of the calculations:
		\href{https://bit.ly/calctut3}{\tt{bit.ly/calctut3}}.

		In the limit as $n \to \infty$, 
		the $n$-sided-polygon approximation to the area of the circle 
		will becomes \emph{exactly} equal to $\pi = 3.141592653589793\ldots$,
		which we write as $\lim_{n \to \infty} A(n) = \pi$.
		Note that $A(n) \neq \pi$ for any finite number $n$ no matter how large.
		It is only in the limit as $n$ goes to infinity that the approximation becomes exact.

	\medskip
	\noindent
	Let's look at another example of a simple math procedure with $n$ steps
	that produces an important number when $n$ goes to infinity.
	% ALT.  that allows us to compute an important number 


	\subsection{Example: Euler's number}
	\label{introduction:eulers_number}

		Suppose you take out a loan with 100\% nominal interest rate.
		This is a very bad loan that nobody would agree to the real world,
		but we'll use it for this example to make the math come out simpler.
		An interest of $100\%$ calculated yearly means at the end of one year,
		you'll owe $(1+100\%) = (1+1)=2$ times the amount you borrowed initially.

		However,
		most banks don't calculate the interest owed only once per year,
		but more often.
		If the bank calculates the interest twice per year,
		during the first six months you'll have accrued $\frac{100\%}{2} = 50\%$ of interest,
		so you'll owe them $(1+50\%) = (1+\frac{1}{2}) = 1.5$ times the initial amount.
		Then during the second six months,
		the amount owed will grow by an additional $(1+50\%) = (1+\frac{1}{2}) = 1.5$,
		so at the end of the year,
		you'll owe $(1+\frac{1}{2})(1+\frac{1}{2}) = 2.25$.

		If the bank computes the interest three times per year,
		the amounted owed after one year is $(1+\frac{1}{3})(1+\frac{1}{3})(1+\frac{1}{3}) = 2.370$.
		If they compute the interest four times per year (quarterly),
		then you'll owe $(1+\frac{1}{4})(1+\frac{1}{4})(1+\frac{1}{4})(1+\frac{1}{4})  = 2.441$.
		Note the amount owed after one year keeps changing,
		as the compounding is performed more frequently.
		In general,
		when the compounding is performed $n$ times per year,
		the amount owed at the end of the year will be
		\[
			\underbrace{
			\left(1 + \tfrac{1}{n} \right)
			\left(1 + \tfrac{1}{n} \right)
			\cdots
			\left(1 + \tfrac{1}{n} \right)
			}_{n \text{ times}}
			= 
			\left(1 + \tfrac{1}{n} \right)^{\!n}.
		\]

		\noindent
		With monthly compounding ($n=12$),
		the amount owed will be $(1 + \tfrac{1}{12})^{12} = 2.613$
		at the end of one year.
		With daily compounding,
		the amount would be $(1 + \tfrac{1}{365})^{365} = 2.715$.
		If computing the interest $n=1000$ times per year,
		the amount ill be $(1 + \tfrac{1}{1000})^{1000} = 2.717$.
		The amount owed keeps increasing,
		but it seems to ``stabilize'' around the value $2.71$.

		What happens if we perform the compounding even more frequently?
		Specifically,
		we want to know what happens if the compound interest interest is calculated infinitely often.
		The infinitely-often calculation corresponds
		to computing the \emph{limit} of expression  $(1 + \frac{1}{n})^n$,
		as $n$ goes to infinity,
		which is written as follows using math notation:
		\[
			\lim_{n\to \infty} \left( 1 + \tfrac{1}{n}\right)^{\!n}
				\;\; = \;\; e
				\;\;= \;\; 2.718281828\ldots.
		\]
		This limit expression \emph{converges} to the value $e = 2.71828\ldots$,
		which is known as \emph{Euler's number}.
		% The number $e$ describes the limit of the annual growth rate of a loan
		If we borrow $\$1000$,
		we'll owe $\$1000e = \$2718.28$ at the end of one~year.		
		%	 compound interest calculation for an annual interest rate of $100\%$
		%	with compounding is performed infinitely often.


	We defined the number $\pi$ as the limit $\lim_{n \to \infty} A(n)$
	and the number $e$ as the limit $\lim_{n\to \infty} \left( 1 + \tfrac{1}{n}\right)^{\!n}$.
	These definition of the numbers $\pi$ and $e$ using as limits
	are go beyond the regular math operations we learn in high school math.
	The limit expression $\lim_{n \to \infty}$ doesn't describer any particular number $n$,
	but the \emph{process} of plugging in large and larger values of $n$.
	% This is what the limit notation $\lim_{n\to \infty} (1 + \frac{1}{n})^n$ means:
	% it describes the behaviour of the expression $(1 + \frac{1}{n})^n$
	% as $n$ goes to infinity.


% TODO: summarize + drive point home => procedures 
%	$\displaystyle  \lim_{n \to \infty} \textrm{proc}(n)$:
%	limit expression that describes the outcome of some computational procedure with $n$ steps,
%	as the number of steps $n$ goes to infinity.
% The parameter $n$ usually describes the number of steps in a given procedure,
% and $\textrm{proc}(n)$ describes the output of this procedure when $n$ steps are used.


		% EULER'S NUMBER VIA SERIES	
		%	Euler's number $e$ can also be obtained from another limit expression:
		%	\[
		%		e	=	1  + 1 + \frac{1}{2!} + \frac{1}{3!} + \frac{1}{4!}  + \cdots
		%			= 	\lim_{n\to \infty} \sum_{k=0}^n \frac{1}{k!}
		%			= 	2.718281828\ldots.
		%	\]
		%	This alternative expression
		%	tells us we can compute $e$ as the sum ($\sum$)
		%	with an infinite number of terms.
		%	Each term comes from a common ``pattern'' $\frac{1}{k!}$,
		%	where $k! = k\!\cdot\!(k-1) \cdots 3\!\cdot\!2\!\cdot\!1$
		%	is the factorial function.
		%	The notation $\sum_{k=0}^n$
		%	describes the summation starting at $k=0$ and going all the way to $k=n$.
		%	The limit $\lim_{n\to \infty}$ tells us the summation has infinitely many terms.
		%	This kind of infinite sum expression are called a \emph{series},
		%	and provides a powerful way to compute quantities by summing together a bunch of terms.
		%	We'll learn more about sequences and series in Section~\ref{sec:sequences_and_series}.







	\subsection{Limits at infinity}
	\label{limits:limits_to_infinity}

		We can use limit expressions to describe
		what happens to a certain function when its input variable tends to infinity.
		Does $f(x)$ approach a finite number,
		or does it keep growing to $\infty$?
		The function $f(x)$ is said to \emph{converge} to $L$
		if the function approaches the value $L$ for large values of $x$:
		\[
			\lim_{x \to \infty} f(x)  =  L.
		\]
		We say ``the limit of $f(x)$ as $x$ goes to infinity is $L$.''
		See Figure~\ref{fig:limit-at-infinity-graph} for an illustration.
		% ALT.
		%	The limit equation $\displaystyle \lim_{x \to \infty} f(x) = L$
		%	states that the  ``limit at infinity'' of the function $f(x)$ is equal to the number $L$.

		\begin{figure}[htb]
			\centering
			\includegraphics[width=0.63212\columnwidth]{figures/calculus/limit-at-infinity-graph.png}
			\vspace{-3mm}
			\caption{	A function $f(x)$ that oscillates up and down initially,
					but  it ``settles down'' close to the value $L$ for large values of $x$.}
			\label{fig:limit-at-infinity-graph}
		\end{figure}


		\subsubsection{Example 1}

			Consider the limit of the function $f(x) = \frac{1}{x}$ as $x$ goes to infinity,
			as illustrated in Figure~\ref{fig:limits_examples}~(a):
			\[
				\lim_{x \to \infty} f(x)
					= 	\lim_{x \to \infty} \tfrac{1}{x}
					= 	0.
			\]
			The function $\tfrac{1}{x}$ never \emph{actually} reaches zero,
			so it would be wrong to write $f(x)=0$ for any $x \in \mathbb{R}$.
			However,
			the expression $\frac{1}{x}$ gets closer and closer to $0$ as $x$ goes to infinity.
			Limits are useful because they allow us describe this tendency as $\displaystyle \lim_{x\to \infty} f(x)=0$.
			% even though $f(x)\neq 0$ for any number $x$.



		\begin{figure}[htb]
			\centering
			\includegraphics[width=0.99\columnwidth]{figures/calculus/limits_examples.pdf}
			% TODO: redo figure with xmax=8
			\vspace{-6mm}
			\caption{	Visual representation of the limit calculations for three functions.}
					%	$\lim_{x\to \infty} \frac{1}{x}$,
					%	$\lim_{x\to \infty} \frac{2x+1}{x}$,
					%	$\lim_{x\to 0^-} H(x)$, and $\lim_{x\to 0^+} H(x)$.}
			\label{fig:limits_examples}
		\end{figure}



		%	% CUTTABLE
		%	The limit expression is a concise way of saying the following precise mathematical statement:
		%	\begin{multline*}
		%	  \textrm{For all } \epsilon>0,
		%	  	 \textrm{ there exists a number } S \textrm{ such that } \\ 
		%		 	\left|f(x) - L\right| <\epsilon
		%			\textrm{ for all } x \textrm{ greater than or equal to } S.
		%	\end{multline*}
		%
		%	\noindent
		%
		%	You can think of this fancy statement
		%	as a formal way that a mathematician can prove $\displaystyle \lim_{x \to \infty} f(x) = L$ is true.
		%	You tell the mathematician a level of $\epsilon$ that would convince you,
		%	and the mathematician must find a starting point~$S$
		%	after which $f(x)$ becomes (and stays) $\epsilon$-close to the limit $L$.
		%	If the mathematician can succeed for all levels of precision $\epsilon$,
		%	not matte show small,
		%	then we have to believe that $\displaystyle \lim_{x \to \infty} f(x) = L$ is true.
		%	% /CUTTABLE


	\subsection{Limit formulas}

		The limit of the sum, difference, product, and quotient of two functions
		are can be computed as follows:
		% is equal to the corresponding operation of the limits of the two functions:
		\begin{align*}	
			\lim_{x \to \infty} (f(x) + g(x)) 	& =  \lim_{x \to \infty} f(x) + \lim_{x \to \infty} g(x), 	\\
			\lim_{x \to \infty} (f(x) - g(x)) 	& =  \lim_{x \to \infty} f(x) - \lim_{x \to \infty} g(x), 	\\
			\lim_{x \to \infty} f(x)g(x) 		& =   \lim_{x \to \infty} f(x) \cdot \lim_{x \to \infty} g(x), \\
			\lim_{x \to \infty} (f(x) / g(x)) & =  \lim_{x \to \infty} f(x) \, / \lim_{x \to \infty} g(x) \, .
			% \lim_{x \to \infty} \frac{f(x)}{g(x)} & =  \frac{ \displaystyle \lim_{x \to \infty} f(x) } { \displaystyle \lim_{x \to \infty} g(x)} \, .
		\end{align*}

		\noindent
		In words,
		these formulas tell us we
		can bring the limit calculations ``inside'' basic arithmetic operations.


		\subsubsection{Example 2}

			Calculate $\lim\limits_{x\to \infty} \frac{2x+1}{x}\,$.
			We're given the function $f(x)=\frac{2x+1}{x}$
			and must determine what the function looks like for very large values of $x$.
			We can rewrite the function as $\frac{2x+1}{x}=2+\frac{1}{x}$
			then apply the sum formula for limits:
			\[
				\lim_{x\to \infty}\!\! \tfrac{2x+1}{x} 
					= \lim_{x\to \infty}\!\left( 2 + \tfrac{1}{x} \right)
					= \lim_{x\to \infty} 2 + \!\lim_{x\to \infty} \tfrac{1}{x} 
					= 2 + 0 = 2.
			\]
			As the denominator $x$ becomes larger and larger,
			the fraction $\frac{1}{x}$ becomes smaller and smaller,
			so $\displaystyle \lim_{x \to \infty} \tfrac{1}{x} = 0$,
			so the second term goes zero,
			leaving only the $2$.
			See Figure~\ref{fig:limits_examples}~(b) for an illustration.



	\subsection{Limits to zero}
	\label{limits:limits_to_zero}

		The limit expression $\lim_{x \to 0} f(x)$
		describes the behaviour of the function $f$ for infinitely small values of $x$.
		The limit $\lim_{x \to 0} f(x)$,
		read ``the limit of $f(x)$ as $x$ goes to zero,''
		asks us to evaluate the function $f$ for inputs like
		$x=0.1$, $x=0.01$, $x=0.001$, $x=0.0001$, etc.
		to see the behaviour of the function for very small values of $x$.

		For example,
		the limit $\lim_{x \to 0} \frac{1}{x} = \infty$.
		In words,
		the function $f(x) = \frac{1}{x}$ ``blows up'' to infinity as $x$ goes to $0$.
		See Figure~\ref{fig:limits_examples}~(a).


	\subsection{Limits to a number}
	\label{limits:limits_to_a_number}

		More generally,
		the limit of $f(x)$ approaching $x=a$ \emph{from the right}
		is denoted $\lim_{x\to a^+} f(x) = \lim_{\delta \to 0} f(a + \delta)$.
		We use the symbol $\delta$ (the Greek letter \emph{delta}) to describes a distance
		that gets smaller and smaller.
		This limit expression that describes the value of the function $f$
		as the input $x$ gets closer and closer to $a$
		with values like $a+0.1$, $a+0.01$, $a+0.001$, $a+0.0001$, etc.
		%
		The limit of $f(x)$ when $x$ approaches \emph{from the left} is defined analogously,
		$\lim_{x\to a^-} f(x)  = \lim_{\delta \to 0} f(a - \delta)$.
		%		describes what happens to $f(x)$ as $x$ approaches $a$ from below
		%		(from the left) with values like $x=a-$, 
		%		with $\delta>0, \delta \to 0$.

		If both limits from the left and from the right at $x=a$
		exist and are equal to each other,
		we say the limit as $x\to a$ exists:
		\[
			\lim_{x\to a} f(x) =  \lim_{x\to a^+} f(x) =  \lim_{x\to a^-} f(x).
		\]
		For the two-sided limit of a function to exist at a point,
		both the limit from the left and the limit from the right must converge to the same number.










	\subsection{Continuity}
	\label{limits:continuity}

		If the function $f(x)$ obeys, $f(a) = L$ and $\lim_{x\to a} f(x) = L$,
		we say the function $f(x)$ is \emph{continuous} at $x=a$.
		Geometrically,
		the graph of the continuous function at $x=a$ is ``smooth'' curve
		that doesn't have any hole or a jump at $x=a$.
		Intuitively,
		when a function is continuous,
		we can draw its graph using a single pen stroke
		without lifting the pen.
		% means the function's graph looks like a smooth curve
		In contrast,
		functions that blow up to infinity or make sudden jumps are not continuous.

		\subsubsection{Example 3}

			The \emph{Heaviside step function} is an example of a function
			with a jump discontinuity.
			It is defined as follows:
			\[
				H(x) \eqdef \begin{cases}
							\; 1, 	& \text{if } x \geq 0 \\
							\; 0, 	& \text{if } x < 0.
						\end{cases}
			\]

			\noindent
			The function is zero for negative values of $x$,
			then suddenly jumps to one at $x=0$,
			as shown in Figure~\ref{fig:limits_examples}~(c).
			The limit as $x$ approaches $x=0$ from the left is $\lim_{x\to 0^-} H(x) = 0$.
			The limit at $x=0$ from the right is $\lim_{x\to 0^+} H(x) = 1$.
			The two limits are different,
			$\lim_{x\to 0^-} H(x) = 0 \neq 1 = \lim_{x\to 0^+} H(x)$,
			so the function is \emph{discontinuous} at $x=0$.


		%	A more mathematically precise way to define continuity is to say the function is equal to its limit for all $x$.
		%	We say a function $f(x)$ is \emph{continuous} at $a$ if the limit of $f$ as $x\to a$ converges to $f(a)$:
		%	\[
		%	 \lim_{x \to a}  f(x) =  f(a).
		%	\]
		%	Remember,
		%	the two-sided limit $\lim_{x\to a}$ requires both the left and the right limit to exist and to be equal.
		%	Thus, the definition of continuity implies the equality $\lim_{x \to a^-}  f(x) =  f(a)$
		%	and $f(a) = \lim_{x \to a^+}  f(x)$,
		%	which correspond to the idea of ``not lifting the pen'' when drawing the graph at $x=a$.

		%	In words,
		%	this means that a function $f(x)$ is continuous at $x=a$
		%	if the limit from the left $\lim_{x \to a^-}  f(x)$
		%	and the limit from the right $\lim_{x \to a^+}  f(x)$
		%	are both equal to the value of the function at $x=a$.
		%	% Take a moment to think about the mathematical definition of continuity at a point.
		%	% Can you connect the math definition to the intuitive idea
		%	% that functions are continuous if they can be drawn without lifting the pen?
		%	Most functions we'll study in calculus are continuous,
		%	but not all functions are.

		%	Functions that are not defined for some value, as well as functions that make sudden jumps, are not continuous.
		%	%		Another examples is the function $f(x)=\frac{2x+1}{x}$ which is discontinuous at $x=0$
		%	%		(because the limit $\lim_{x \to 0}  f(x)$ doesn't exist and $f(0)$ is not defined).
		%	For example,
		%	consider the function $f : \mathbb{R} \setminus \{0\} \to \mathbb{R}$ defined by
		%	\[
		%		f(x)
		%		=\frac{ | x-3| }{x-3} 
		%		= \left\{ 	\begin{array}{rl}
		%				1	\quad	&  \mathrm{  if } \;  x > 3, \\
		%				-1	\quad	&  \mathrm{  if } \;  x < 3.
		%		                        \end{array}                    \right.
		%	\]
		%	The function $f$ is continuous everywhere on the real line except at $x=3$.
		%	Since this function $f$ is ``missing'' only at a single point,
		%	we can try to ``patch it'' by filling in the missing value.
		%	Consider the function $g : \mathbb{R} \to \mathbb{R}$ defined as
		%	\[
		%		g(x)
		%		= \left\{ 	\begin{array}{rl}
		%				1	\quad	&  \mathrm{  if }\;  x > 3, \\
		%				1	\quad	&  \mathrm{  if }\;  x = 3, \\
		%				-1	\quad	&  \mathrm{  if } \;  x < 3.
		%		                        \end{array}                    \right.		
		%	\]
		%	The function $g$ is \emph{continuous from the right} at the point $x=3$,
		%	since $\lim_{x \to 3^+} g(x)=1=g(3)$.
		%	However,
		%	taking the limit from the left,
		%	we find $\lim_{x \to 3^-} g(x)=-1 \neq g(3)$,
		%	which tells us $g$ is not continuous from the left.
		%	We say the function $g$ has a \emph{jump discontinuity} at $x=3$.

		% Khan Academy
		% https://www.youtube.com/watch?v=Y7sqB1e4RBI

		%	\paragraph{Example 3}	
		%		We can calculate the limit $\displaystyle\lim_{x\to 5} \frac{2x+1}{x}$ as follows:
		%		\[
		%		 \lim_{x\to 5} \frac{2x+1}{x}
		%		  = \frac{2(5)+1}{5}
		%		  = \frac{11}{5}.
		%		\]
		%		There is nothing tricky going on here---we plug the number $5$ into the equation, and voila. 
		%		The function $f(x)=\frac{2x+1}{x}$ is continuous at the value $x=5$, so the limit of the function 
		%		as $x\to 5$ is equal to the value of the function $\displaystyle\lim_{x\to 5} f(x) = f(5)$.
		%		% This is true in general for any continuous function.





	\subsection{Computing limits using SymPy}
	
		We can use SymPy to compute limit expression,
		which allows us to check the answers we obtain using pen-and-paper calculations.
		We'll start by importing the \tt{sympy} module under the alias \tt{sp},
		defining the symbolic variable $\tt{n} = n$,
		which we can then use to write various expressions.

		\begin{codeblock}[sympy-e-from-limit]
		>>> import sympy as sp
		>>> n = sp.symbols("n")
		\end{codeblock}

		To compute limits,
		we use the SymPy function \tt{sp.limit(expr,var,value)},
		which computes the limit of the expression \tt{expr},
		as the variable \tt{var} approaches \tt{value}.
		For limits toward infinity,
		we use the special symbol \texttt{sp.oo} (two lowercase \texttt{o}s),
		which is a clever name chosen because it resembles the infinity symbol $\infty$.

		% We can use SymPy to check the limit calculation we saw above.		
		% EXAMPLE  e
		Euler's number is defined as the limit
		$e \eqdef \lim_{n\to \infty} \left( 1 + \frac{1}{n}\right)^{n}$.
		To compute this limit using SymPy,
		we call \tt{sp.limit} on the expression \tt{(1+1/n)**n}
		as $\tt{n}$ goes to infinity $\infty = \texttt{sp.oo}$:

		\begin{codeblock}[sympy-e-from-limit]
		>>> sp.limit((1+1/n)**n, n, sp.oo)
		E
		>>> sp.limit((1+1/n)**n, n, sp.oo).evalf(40)
		2.718281828459045235360287471352662497757
		\end{codeblock}

		\noindent
		The result of \tt{sp.limit} is the exact value $e$
		which is represented symbolically as \tt{E}.
		On the second line,
		we used the method \tt{.evalf(40)} 
		to compute an approximation to $e$ to 40 decimals.


		% EXAMPLE 1/x
		Let's now compute the limits $\lim_{x \to \infty} \tfrac{1}{x}$
		and $\lim_{x \to 0^+} \tfrac{1}{x}$.
		We fist define the symbol \tt{x}
		then call the function \tt{sp.limit} to evaluate the two limits
		involving the expression $\tt{1/x} = \frac{1}{x}$:

		\begin{codeblock}[]
		>>> x = sp.symbols("x")
		>>> sp.limit(1/x, x, sp.oo)
		0
		>>> sp.limit(1/x, x, 0)
		oo
		\end{codeblock}

		\noindent
		SymPy confirms that $\lim_{x \to \infty} \tfrac{1}{x} = 0$
		and $\lim_{x \to 0^+} \tfrac{1}{x} = \infty$,
		as calculated earlier.
		See Figure~\ref{fig:limits_examples}~(a) for an illustration.


		% EXAMPLE (2x+1)/x		
		Here is another example,
		that computes the limit of the fraction $\frac{2x+1}{x}$ as $x$ goes to infinity,
		which is illustrated in Figure~\ref{fig:limits_examples}~(b).

		\begin{codeblock}[]
		>>> sp.limit((2*x+1)/x, x, sp.oo)
		2
		\end{codeblock}

		% EXAMPLE  Heaviside
		\noindent
		To calculate the limit form the left and the right of a number,
		we must provide a fourth argument \tt{"-"} or \tt{"+"}.
		The following SymPy calculations confirm the limits of the Heaviside step function
		when approaching $x=0$ from the left and from the right.

		\begin{codeblock}[]
		>>> from sympy import Heaviside
		>>> sp.limit(Heaviside(x,1), x, 0, "-")
		0
		>>> sp.limit(Heaviside(x,1), x, 0, "+")
		1
		\end{codeblock}

		\noindent
		See Figure~\ref{fig:limits_examples}~(c) for an illustration.


		% TODO: ADD MORE LIMIT EXAMPLES
		%	Here are some other examples of limits:

		% NOTEBOOK ONLY
		%	Infinity is not a number but a process: the process of counting forever.
		%	Thus, $\infty + 1 = \infty$, $\infty$ is greater than any finite number, and $1/\infty = 0$.
		%	\begin{codeblock}[]
		%	>>> from sympy import oo
		%	>>> oo+1
		%	oo
		%	>>> 5000 < oo 
		%	True
		%	>>> 1/oo
		%	0
		%	\end{codeblock}

		% BONUS SYMPY EXAMPLES
		%	The SymPy function \tt{limit} allows us to compute limit expressions.
		%	For example,
		%	if we want to see if the exponential function $e^x$ or the polynomial function $x^{100}$ grows faster
		%	in the limit as $x$ goes to infinity,
		%	The code for computing the limit of the ratio between these two expressions is
		%
		%	\begin{codeblock}[sympy-limit-exp-over-x-100]
		%	>>> from sympy import limit, exp, oo
		%	>>> limit(exp(x)/x**100, x, oo) 
		%	oo
		%	\end{codeblock}
		%
		%	\noindent
		%	The answer $\infty$,
		%	written as \tt{oo} (two lowercase letters ``o''),
		%	tells us exponential functions grow faster than polynomial functions.
		%	%	This result has implications in computer science,
		%	%	where algorithms whose running time grows exponentially with the size of their input are considered bad





	\subsection{Applications of limits}

		Limits are important because they are used in the formal definitions of derivatives, integrals, and series:

		\begin{itemize}

			\item The derivative function $f^{\prime\!}(x)$
				describe the instantaneous rate change of the function $f(x)$.
				In Section~\ref{sec:derivatives} we'll learn how to calculate derivatives
				by evaluating a limit of the form $\lim_{\delta \to 0}$.

			\item The integral $\int_a^b f(x) \, dx$
				describes the area under the graph of the function $f(x)$ between $x=a$ and $x=b$.
				In Section~\ref{sec:integrals}
				we'll learn how to compute integrals by splitting up area into $n$ rectangular strips
				and taking the limit $\lim_{n \to \infty}$.

			\item The series $\sum_{k=1}^n a_k$ describes
				the sum of all the first $n$ terms in the sequence $a_k$.
				In Section~\ref{sec:sequences_and_series},
				we'll learn how to compute infinite series by taking $\lim_{n \to \infty}$.

		\end{itemize}


% Many important math and science quantities are defined as limit expressions.

% LEAD OUT	
%	In the remainder of this tutorial we'll use limits to evaluate derivatives, integrals, and series expressions.
%	In each of these domains,
%	limit expressions will help us make precise statements
%	that describe calculus procedures with infinite small lengths and infinite number of steps.









% TODO: Limit exercises








% \subsubsection{Example: split up line}
%		Let's begin with a simple example.
%		Say you have a string of length $\ell$ and you want to divide it into infinitely many, infinitely short segments.
%		There are infinitely many segments,
%		and they are infinitely short, so together the segments add to the string's total length $\ell$.
%
%		It's easy enough to describe this process in words.
%		Now let's describe the same process using the notion of a limit.
%		If we divide the length of the string $\ell$ into $N$ equal pieces then each piece will have a length of
%		\[
%		   \delta = \frac{\ell}{N}  \,.
%		\]
%		Let's make sure that $N$ pieces of length $\delta$ added together equal the string's total length: 
%		\[
%		 N \delta = N \frac{\ell}{N} = \ell.
%		\]
%		
%		\noindent
%		Now imagine what happens when the variable $N$ becomes larger and larger.
%		The larger $N$ becomes, the shorter the pieces of string will become.
%		In fact, if $N$ goes to infinity (written $N \to \infty$),
%		then the pieces of string will have zero length:
%		\[
%		 \lim_{N\to \infty}  \delta = \lim_{N\to \infty} \frac{\ell}{N} = 0.
%		\]
%		In the limit as $N \to \infty$, the pieces of string are \emph{infinitely small}.
%		
%		Note we can still add the pieces of string together to obtain the whole length:
%		\[
%		 \lim_{N\to \infty}  \left( N \delta \right) 
%		 = 
%		 \lim_{N\to \infty}  \left( N \frac{\ell}{N} \right)
%		 = \ell.
%		\]
%		Even if the pieces of string are \emph{infinitely small},
%		because there are \emph{infinitely many} of them,
%		they still add to $\ell$.
%
%			splitting up an interval into $n$ segments, then making $n$ go to infinity
%			splitting with an infinite number of segments
%			\begin{codeblock}[sympy-limit-sement-zero-length]
%			>>> from sympy import limit, oo, summation
%			>>> delta = (b - a)/n
%			>>> limit(delta, n, oo)
%			0
%			\end{codeblock}
%		
%			\begin{codeblock}[sympy-limit-sements-add-to-interval]
%			>>> summation(delta, (i, 0, n-1))
%			b - a				
%			\end{codeblock}
%
%		The take-home message is that as long as you clearly define your limits,
%		you can use infinitely small numbers in your calculations.
%		The notion of a limit is one of the central ideas in this course.

